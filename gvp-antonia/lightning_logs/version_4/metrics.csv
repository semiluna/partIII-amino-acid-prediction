train_loss,epoch,step
2.744612455368042,0,0
3.1737465858459473,0,1
3.9435062408447266,0,2
3.2511544227600098,0,3
4.568567752838135,0,4
3.722240686416626,0,5
3.558619499206543,0,6
4.158112049102783,0,7
3.970411777496338,0,8
3.854365110397339,0,9
3.576272964477539,0,10
3.13177490234375,0,11
3.3401060104370117,0,12
3.462587833404541,0,13
3.243546724319458,0,14
3.311755657196045,0,15
3.257962226867676,0,16
3.072680950164795,0,17
2.9839224815368652,0,18
2.9493300914764404,0,19
2.6945688724517822,0,20
2.8375470638275146,0,21
3.144665002822876,0,22
3.28696346282959,0,23
3.5799877643585205,0,24
3.3354711532592773,0,25
3.4897775650024414,0,26
2.8472747802734375,0,27
4.26413631439209,0,28
3.083799123764038,0,29
3.3968396186828613,0,30
2.995344638824463,0,31
3.0123815536499023,0,32
4.250208377838135,0,33
3.215935230255127,0,34
3.0675511360168457,0,35
3.6844053268432617,0,36
3.4405789375305176,0,37
3.469774007797241,0,38
2.9713542461395264,0,39
3.1332173347473145,0,40
3.3684659004211426,0,41
3.1564011573791504,0,42
3.134303331375122,0,43
3.2839388847351074,0,44
3.1584978103637695,0,45
3.167771816253662,0,46
2.610870361328125,0,47
3.0256242752075195,0,48
3.0591721534729004,0,49
3.1383376121520996,0,50
3.175412654876709,0,51
3.2291810512542725,0,52
3.283097743988037,0,53
3.234302043914795,0,54
2.5682129859924316,0,55
3.2773687839508057,0,56
2.7900681495666504,0,57
2.992197036743164,0,58
3.1905124187469482,0,59
